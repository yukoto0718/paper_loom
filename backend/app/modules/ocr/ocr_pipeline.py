# backend/app/modules/ocr/ocr_pipeline.py

import subprocess
import json
import shutil
import sys
import asyncio
from pathlib import Path
from typing import Dict
from loguru import logger

try:
    import torch
    CUDA_AVAILABLE = torch.cuda.is_available()
except ImportError:
    CUDA_AVAILABLE = False

class OCRPipeline:
    """
    ä½¿ç”¨ MinerU çš„ç®€åŒ–æµç¨‹
    æ‰€æœ‰å¤æ‚é€»è¾‘ï¼ˆæ–‡æœ¬åˆå¹¶ã€æ’åºã€å›¾ç‰‡å®šä½ï¼‰ç”± MinerU å¤„ç†
    """
    
    def __init__(self, ocr_model_size: str = "small"):
        self.ocr_model_size = ocr_model_size
        self.device = "cuda" if CUDA_AVAILABLE else "cpu"
        self.mineru_available = self._check_mineru_available()
    
    def _check_mineru_available(self):
        """æ£€æŸ¥ MinerU æ˜¯å¦å¯ç”¨"""
        try:
            # æ£€æŸ¥ CLI æ˜¯å¦å¯ç”¨
            result = subprocess.run(
                ["mineru", "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode == 0:
                logger.info(f"âœ… MinerU CLI å¯ç”¨: {result.stdout.strip()} (è®¾å¤‡: {self.device})")
                return True
        except (FileNotFoundError, subprocess.TimeoutExpired):
            pass
        
        logger.error("âŒ MinerU ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install -U mineru[core]")
        return False
    
    async def process(self, pdf_path: Path, output_dir: Path) -> Dict:
        """
        å®Œæ•´å¤„ç†æµç¨‹ - ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œé¿å…é˜»å¡
        """
        logger.info(f"å¼€å§‹å¤„ç†: {pdf_path.name} (è®¾å¤‡: {self.device})")
        
        if not self.mineru_available:
            # å¦‚æœ MinerU ä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            return await self._use_fallback(pdf_path, output_dir)
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•ï¼ˆMinerU ä¼šåœ¨è¿™é‡Œç”Ÿæˆæ–‡ä»¶ï¼‰
        temp_output = output_dir / "mineru_temp"
        temp_output.mkdir(exist_ok=True, parents=True)
        
        try:
            # 1. å¼‚æ­¥è°ƒç”¨ MinerU å¤„ç†
            await self._run_mineru_async(pdf_path, temp_output)
            
            # 2. æ•´ç†è¾“å‡ºæ–‡ä»¶
            final_output = self._organize_output(
                pdf_path,
                temp_output,
                output_dir
            )
            
            # 3. è¯»å– Markdown
            markdown = final_output['md_file'].read_text(encoding='utf-8')
            
            # 4. æå–ç»Ÿè®¡ä¿¡æ¯
            stats = self._extract_stats(
                final_output['content_list'],
                output_dir=output_dir,
                markdown_content=markdown
            )
            
            logger.info("âœ… MinerU å¤„ç†å®Œæˆï¼")
            
            return {
                'markdown': markdown,
                'output_dir': str(output_dir),
                'stats': stats,
                'mineru_success': True
            }
        
        except Exception as e:
            logger.warning(f"MinerU å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_output.exists():
                shutil.rmtree(temp_output)
            # ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            return await self._use_fallback(pdf_path, output_dir)
    
    async def _run_mineru_async(self, pdf_path: Path, output_dir: Path):
        """
        è°ƒç”¨ MinerU CLI - Windowså…¼å®¹ç‰ˆæœ¬
        """
        logger.info("è°ƒç”¨ MinerU...")
        
        # æ„å»ºå‘½ä»¤ - ä½¿ç”¨GPUåŠ é€Ÿ
        cmd = [
            "mineru",
            "-p", str(pdf_path),
            "-o", str(output_dir),
            
            # âœ… å…³é”®é…ç½®
            "-b", "pipeline",           # ä½¿ç”¨ pipeline backend
            "--lang", "en",             # è‹±æ–‡OCR
            "-t", "false",              # â—è¡¨æ ¼æˆªå›¾æ¨¡å¼ï¼ˆä¸è¯†åˆ«ï¼‰
            "-f", "true",               # å…¬å¼è¯†åˆ«
            "-d", "cuda",               # ğŸš€ ä½¿ç”¨GPUåŠ é€Ÿ (ä½ çš„RTX 4060)
        ]
        
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # Windowså…¼å®¹çš„å¼‚æ­¥æ‰§è¡Œ
        try:
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥subprocess
            import concurrent.futures
            loop = asyncio.get_event_loop()
            
            def run_mineru_sync():
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
                    shell=True    # Windowséœ€è¦shell=True
                )
                return result
            
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ
            with concurrent.futures.ThreadPoolExecutor() as pool:
                result = await loop.run_in_executor(pool, run_mineru_sync)
            
            if result.returncode != 0:
                error_msg = result.stderr if result.stderr else result.stdout
                logger.error(f"MinerU å¤„ç†å¤±è´¥: {error_msg}")
                raise Exception(f"MinerU å¤„ç†å¤±è´¥: {error_msg}")
            
            logger.info("âœ… MinerU å¤„ç†å®Œæˆ")
            
        except subprocess.TimeoutExpired:
            logger.error("âŒ MinerU å¤„ç†è¶…æ—¶ (5åˆ†é’Ÿ)")
            raise Exception("MinerU å¤„ç†è¶…æ—¶ï¼Œè¯·æ£€æŸ¥PDFæ–‡ä»¶æˆ–é‡è¯•")
        except Exception as e:
            logger.error(f"MinerU æ‰§è¡Œé”™è¯¯: {e}")
            raise
    
    async def _use_fallback(self, pdf_path: Path, output_dir: Path) -> Dict:
        """
        ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆå¤„ç†PDF
        """
        try:
            from .fallback_pipeline import FallbackPipeline
            fallback = FallbackPipeline()
            result = await fallback.process(pdf_path, output_dir)
            result['fallback_used'] = True
            return result
        except Exception as e:
            logger.error(f"å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e}")
            raise Exception(f"æ‰€æœ‰å¤„ç†æ–¹æ¡ˆéƒ½å¤±è´¥: {e}")
    
    def _organize_output(
        self,
        pdf_path: Path,
        temp_output: Path,
        final_output: Path
    ) -> Dict:
        """
        æ•´ç† MinerU çš„è¾“å‡ºæ–‡ä»¶
        
        MinerU è¾“å‡ºç»“æ„å¯èƒ½ä¸åŒï¼Œéœ€è¦çµæ´»å¤„ç†
        """
        pdf_name = pdf_path.stem
        
        # æŸ¥æ‰¾å¯èƒ½çš„è¾“å‡ºç›®å½•ç»“æ„
        possible_dirs = [
            temp_output / "auto",
            temp_output / pdf_name / "auto",
            temp_output
        ]
        
        auto_dir = None
        for possible_dir in possible_dirs:
            if possible_dir.exists():
                auto_dir = possible_dir
                logger.info(f"æ‰¾åˆ° MinerU è¾“å‡ºç›®å½•: {auto_dir}")
                break
        
        if not auto_dir:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„æ–‡ä»¶
            md_files = list(temp_output.rglob("*.md"))
            if md_files:
                auto_dir = temp_output
                logger.info(f"ä½¿ç”¨æ ¹ç›®å½•ä½œä¸ºè¾“å‡ºç›®å½•ï¼Œæ‰¾åˆ° {len(md_files)} ä¸ªMDæ–‡ä»¶")
            else:
                raise Exception(f"MinerU è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œæ£€æŸ¥: {temp_output}")
        
        # æŸ¥æ‰¾ Markdown æ–‡ä»¶
        md_files = list(auto_dir.rglob("*.md"))
        if not md_files:
            raise Exception(f"åœ¨ {auto_dir} ä¸­æœªæ‰¾åˆ° Markdown æ–‡ä»¶")
        
        md_file = md_files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„MDæ–‡ä»¶
        logger.info(f"æ‰¾åˆ° Markdown æ–‡ä»¶: {md_file}")
        
        # æŸ¥æ‰¾ content_list æ–‡ä»¶
        content_list_files = list(auto_dir.rglob("*content_list.json"))
        content_list_file = content_list_files[0] if content_list_files else None
        
        # æŸ¥æ‰¾å›¾ç‰‡ç›®å½•
        images_dirs = list(auto_dir.rglob("images"))
        images_dir = images_dirs[0] if images_dirs else None
        
        # ç§»åŠ¨æ–‡ä»¶åˆ°æœ€ç»ˆè¾“å‡ºç›®å½•
        final_md = final_output / "output.md"
        final_images = final_output / "images"
        
        # å¤åˆ¶ Markdown (å¤„ç†ç¼–ç é—®é¢˜)
        try:
            # å°è¯•UTF-8ç¼–ç 
            content = md_file.read_text(encoding='utf-8')
            final_md.write_text(content, encoding='utf-8')
        except UnicodeDecodeError:
            # å¦‚æœUTF-8å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
            try:
                content = md_file.read_text(encoding='cp932')
                final_md.write_text(content, encoding='utf-8')
            except UnicodeDecodeError:
                # æœ€åå°è¯•latin-1
                content = md_file.read_text(encoding='latin-1')
                final_md.write_text(content, encoding='utf-8')
        
        # å¤åˆ¶å›¾ç‰‡ç›®å½•
        if images_dir and images_dir.exists():
            if final_images.exists():
                shutil.rmtree(final_images)
            shutil.copytree(images_dir, final_images)
        
        # è¯»å– content_list
        content_list = {}
        if content_list_file and content_list_file.exists():
            try:
                with open(content_list_file, 'r', encoding='utf-8') as f:
                    content_list = json.load(f)
            except UnicodeDecodeError:
                try:
                    with open(content_list_file, 'r', encoding='cp932') as f:
                        content_list = json.load(f)
                except UnicodeDecodeError:
                    with open(content_list_file, 'r', encoding='latin-1') as f:
                        content_list = json.load(f)
        
        return {
            'md_file': final_md,
            'images_dir': final_images,
            'content_list': content_list
        }
    
    def _extract_stats(self, content_list: Dict, output_dir: Path = None, markdown_content: str = None) -> Dict:
        """
        æå–ç»Ÿè®¡ä¿¡æ¯ - ä»content_listæˆ–å®é™…æ–‡ä»¶ç»Ÿè®¡
        """
        stats = {
            'total_pages': 0,
            'total_elements': 0,
            'tables': 0,
            'figures': 0,
            'formulas': 0,
            'total_images': 0
        }
        
        # å¦‚æœcontent_listå­˜åœ¨ï¼Œä½¿ç”¨å®ƒç»Ÿè®¡
        if content_list and isinstance(content_list, list):
            for page in content_list:
                stats['total_pages'] += 1
                
                # ç»Ÿè®¡å„ç±»å…ƒç´ 
                for block in page.get('preproc_blocks', []):
                    stats['total_elements'] += 1
                    
                    block_type = block.get('type', '')
                    if block_type == 'table':
                        stats['tables'] += 1
                    elif block_type == 'image':
                        stats['figures'] += 1
                    elif block_type in ['equation', 'inline_equation']:
                        stats['formulas'] += 1
        
        # å¦‚æœcontent_listä¸å­˜åœ¨æˆ–ç»Ÿè®¡ä¸º0ï¼Œä½¿ç”¨å®é™…æ–‡ä»¶ç»Ÿè®¡
        if stats['figures'] == 0 and output_dir:
            # ç»Ÿè®¡å®é™…å›¾ç‰‡æ–‡ä»¶
            images_dir = output_dir / "images"
            if images_dir.exists():
                image_files = list(images_dir.rglob("*.png")) + list(images_dir.rglob("*.jpg")) + list(images_dir.rglob("*.jpeg"))
                stats['figures'] = len(image_files)
                stats['total_images'] = len(image_files)
        
        # ä»markdownå†…å®¹ç»Ÿè®¡è¡¨æ ¼å’Œå›¾ç‰‡å¼•ç”¨
        if markdown_content:
            # ç»Ÿè®¡markdownä¸­çš„å›¾ç‰‡å¼•ç”¨
            md_images = markdown_content.count('![')
            if md_images > stats['figures']:
                stats['figures'] = md_images
            
            # ç»Ÿè®¡markdownä¸­çš„è¡¨æ ¼ï¼ˆç®€å•çš„è¡¨æ ¼æ£€æµ‹ï¼‰
            tables = markdown_content.count('|--') + markdown_content.count('|---')
            if tables > stats['tables']:
                stats['tables'] = tables
            
            # ç»Ÿè®¡å…¬å¼ï¼ˆLaTeXæ ¼å¼ï¼‰
            formulas = markdown_content.count('$$') // 2 + markdown_content.count('$') // 2
            if formulas > stats['formulas']:
                stats['formulas'] = formulas
        
        # ç¡®ä¿è‡³å°‘æœ‰ä¸€äº›åŸºæœ¬ç»Ÿè®¡
        if stats['total_pages'] == 0 and markdown_content:
            # ä»markdownå†…å®¹ä¼°ç®—é¡µæ•°ï¼ˆæ¯é¡µçº¦500-1000å­—ç¬¦ï¼‰
            char_count = len(markdown_content)
            stats['total_pages'] = max(1, char_count // 800)
        
        return stats
